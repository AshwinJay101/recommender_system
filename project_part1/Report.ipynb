{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business objective:\n",
    "Our recommendation system comes up with the list of candidate movies and recommends the highly-rated ones to a specific user to achieve personalization goal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms: \n",
    "\n",
    "We explored various memory and model based algorithms \n",
    "\n",
    "Baseline Approach \n",
    "\n",
    "Memory based algorithms: <br>\n",
    "1) KNN Basic <br>\n",
    "2) KNN with Means <br>\n",
    "3) KNN with Zscore <br>\n",
    "4) KNN Baseline <br>\n",
    "\n",
    "Model based algorithms: <br>\n",
    "1) NMF (Non-negative Matrix Factorization) <br>\n",
    "2) SVD <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results:\n",
    "\n",
    "### Baseline Approach:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithms in this section try to minimize the following regularized squared error: <br>\n",
    "\n",
    "$$\\sum_{r_{ui} \\in R_{train}} \\left(r_{ui} - (\\mu + b_u + b_i)\\right)^2 +\n",
    "\\lambda \\left(b_u^2 + b_i^2 \\right).$$\n",
    " \n",
    "b_u: the observed deviation of user u <br>\n",
    "b_i: the observed deviation of item i <br>\n",
    "\n",
    "Baselines can be estimated in the following two ways: <br>\n",
    "Alternating Least Squares (ALS) <br>\n",
    "The hyperparameters to be tuned are: <br>\n",
    "\treg_i: the regularization parameters for items <br>\n",
    "\treg_u: the regularization parameters for users <br>\n",
    "\tn_epochs: the number of iteration of the ALS procedure <br>\n",
    "\n",
    "Stochastic Gradient Descent (SGD) <br>\n",
    "The hyperparameters to be tuned are: <br>\n",
    "\treg: the regularization parameter of the cost function that is optimized <br>\n",
    "\tlearning_rate: the learning rate of SGD <br>\n",
    "\tn_epochs: the number of iteration of the SGD procedure <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Results:\n",
    "\n",
    "Code for Baseline approach can be found in \"part1_baseline.ipynb\"\n",
    "\n",
    "In one of the KNN algorithms, KNNBaseline, we can take into account a baseline rating. We therefore did the grid search on baselines to find the optimal combination of hyper parameters giving the best performance and used the testing dataset to check the accuracy of our tuned model. While comparing the performance of two estimation methods, ALS and SGD, we found that the overall performance is better while using ALS (RMSE is lower), 94.33%, than using SGD, 94.41%. <br>\n",
    " \n",
    "  ALS (RMSE: 94.33%) <br>\n",
    "n_epochs: 20 <br>\n",
    "reg_i: 1 <br>\n",
    "reg_u: 5 <br>\n",
    "\n",
    "SGD (RMSE: 94.41%) <br>\n",
    "   learning_rate: 0.005 <br>\n",
    "n_epochs: 50 <br>\n",
    "reg: 0.02 <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used four different variations of KNN. They are KNN Basic, KNN with Means, KNN with Z-Score, KNN Baseline.\n",
    "Notation: <br>\n",
    "\n",
    "k: The maximum number of neighbors to take into account <br>\n",
    "$ N_i^k(u) $ : The set consisting of at most k neighbors of user u who have rated item i <br>\n",
    "$ N_u^k(i) $ : The set consisting of at most k neighbors of item i rated by user u <br>\n",
    "$ sim(u,v) $ : Similarity of user u to user v <br>\n",
    "$ sim(i,j) $ : Similarity of item i to item j <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the following similarity metrics: Mean Squared Difference similarity (MSD), Cosine Similarity, Pearson Correlation Similarity, Pearson Correlation with Baseline Similarity.\n",
    "\n",
    "Accuracy Metric used: RMSE (Root Mean Squared Error)\n",
    "\n",
    "### i) KNN Basic: <br>\n",
    "$\\hat{r}_{ui}$ : Predicted rating of user u for item i <br>\n",
    "User Based: <br>\n",
    "$ \\hat{r}_{ui} = \\frac{\n",
    "\\sum\\limits_{v \\in N^k_i(u)} \\text{sim}(u, v) \\cdot r_{vi}}\n",
    "{\\sum\\limits_{v \\in N^k_i(u)} \\text{sim}(u, v)} $ \n",
    "\n",
    "Item Based: <br>\n",
    "$ \\hat{r}_{ui} = \\frac{\n",
    "\\sum\\limits_{j \\in N^k_u(i)} \\text{sim}(i, j) \\cdot r_{uj}}\n",
    "{\\sum\\limits_{j \\in N^k_u(j)} \\text{sim}(i, j)} $\n",
    "\n",
    "### ii) KNN with Means:\n",
    "Here we take into account the mean ratings of each user and mean ratings for each item in user-based and item-based approaches respectively. <br>\n",
    "\n",
    "User Based: <br>\n",
    "$ \\hat{r}_{ui} = \\mu_u + \\frac{ \\sum\\limits_{v \\in N^k_i(u)}\n",
    "\\text{sim}(u, v) \\cdot (r_{vi} - \\mu_v)} {\\sum\\limits_{v \\in\n",
    "N^k_i(u)} \\text{sim}(u, v)} $\n",
    "\n",
    "Item Based: <br>\n",
    "$ \\hat{r}_{ui} = \\mu_i + \\frac{ \\sum\\limits_{j \\in N^k_u(i)}\n",
    "\\text{sim}(i, j) \\cdot (r_{uj} - \\mu_j)} {\\sum\\limits_{j \\in\n",
    "N^k_u(i)} \\text{sim}(i, j)} $\n",
    "\n",
    "### iii) KNN with Z score: <br>\n",
    "Here we take into account the z-score normalization of each user.\n",
    "\n",
    "User Based: <br>\n",
    "$ \\hat{r}_{ui} = \\mu_u + \\sigma_u \\frac{ \\sum\\limits_{v \\in N^k_i(u)}\n",
    "\\text{sim}(u, v) \\cdot (r_{vi} - \\mu_v) / \\sigma_v} {\\sum\\limits_{v\n",
    "\\in N^k_i(u)} \\text{sim}(u, v)} $\n",
    "\n",
    "Item Based: <br>\n",
    "$ \\hat{r}_{ui} = \\mu_i + \\sigma_i \\frac{ \\sum\\limits_{j \\in N^k_u(i)}\n",
    "\\text{sim}(i, j) \\cdot (r_{uj} - \\mu_j) / \\sigma_j} {\\sum\\limits_{j\n",
    "\\in N^k_u(i)} \\text{sim}(i, j)} $\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iv) KNN Baseline:\n",
    "\n",
    "Here we take into account the baseline ratings. <br> \n",
    "\n",
    "User Based:\n",
    "\n",
    "$ \\hat{r}_{ui} = b_{ui} + \\frac{ \\sum\\limits_{v \\in N^k_i(u)}\n",
    "\\text{sim}(u, v) \\cdot (r_{vi} - b_{vi})} {\\sum\\limits_{v \\in\n",
    "N^k_i(u)} \\text{sim}(u, v)} $\n",
    "\n",
    "Item Based: \n",
    "\n",
    "$ \\hat{r}_{ui} = b_{ui} + \\frac{ \\sum\\limits_{j \\in N^k_u(i)}\n",
    "\\text{sim}(i, j) \\cdot (r_{uj} - b_{uj})} {\\sum\\limits_{j \\in\n",
    "N^k_u(j)} \\text{sim}(i, j)} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"knn_tests_100k.py\" : The source code to implement the KNN algorithms in Surprise (using 100k dataset) and run the grid search tests to find optimal hyperparameters for each algorithm. <br>\n",
    "\n",
    "\"KNNBaselineTests.py\" : The source code used to analyze performance of our chosen memory-based algorithm (KNN Baseline) against larger datasets. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
